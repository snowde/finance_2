{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import talib as ta\n",
    "from glob import glob\n",
    "import pdb\n",
    "from ipykernel import kernelapp as app\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import itertools as it\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "import sklearn\n",
    "\n",
    "from __future__ import division\n",
    "import random \n",
    "def warn(*args, **kwargs): pass\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann_cusip = pd.read_csv(\"ann_cusip_bo.csv\", dtype=str)\n",
    "ann_cusip[\"CUSIP\"]= ann_cusip[\"CUSIP\"].map(lambda x: x[:6] + '10')\n",
    "ann_tic = pd.read_csv(\"ann_tic_bo.csv\", dtype=str)\n",
    "\n",
    "ann_cusip = pd.read_csv(\"ann_cusip_bo.csv\", dtype=str)\n",
    "ann_cusip[\"CUSIP\"]= ann_cusip[\"CUSIP\"].map(lambda x: x[:6] + '10')\n",
    "ann_tic = pd.read_csv(\"ann_tic_bo.csv\", dtype=str)\n",
    "\n",
    "\n",
    "connect = pd.merge(ann_cusip, ann_tic, left_on=[\"ANNDATS_ACT\", \"OFTIC\"], right_on=[\"anndats\", \"OFTIC\"], how=\"outer\")\n",
    "\n",
    "#connect.drop(\"STATPERS\",1, inplace=True)\n",
    "connect.drop_duplicates(inplace=True)\n",
    "connect.dropna(inplace=True)\n",
    "\n",
    "prices = pd.read_csv(\"prices_bo.csv\", dtype=str)\n",
    "\n",
    "prices[\"CUSIP\"]= prices[\"CUSIP\"].map(lambda x: x[:6] + '10')\n",
    "\n",
    "fiscal = pd.read_csv(\"fiscal_bo.csv\", dtype=str)\n",
    "fiscal.dropna(inplace=True)\n",
    "fiscal[\"cusip\"] = fiscal[\"cusip\"].dropna()\n",
    "\n",
    "fiscal[\"cusip\"]= fiscal[\"cusip\"].map(lambda x: x[:6] + '10')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "merged_2 = pd.merge(prices, fiscal, left_on=[\"date\", \"CUSIP\"], right_on=[\"rdq\", \"cusip\"], how=\"outer\")\n",
    "merged_2.to_csv(\"merged_2_bo.csv\")\n",
    "merged_3 = pd.merge(merged_2, connect, left_on=[\"date\", \"CUSIP\"], right_on=[\"anndats\",\"CUSIP\"], how=\"outer\")\n",
    "merged_3.to_csv(\"merged_3_bo.csv\")\n",
    "merged = merged_3.fillna(method=\"backfill\")\n",
    "merged = merged.fillna(method=\"ffill\")\n",
    "merged.to_csv(\"merged_bo.csv\")\n",
    "\n",
    "merged.rename(columns={'BID':'close', 'ASKHI':'high', 'BIDLO':'low', 'OPENPRC':'open', 'surpmean':'estimate', 'datadate_x':'datadate', 'tic_x':'ticker', 'gvkey_x':'gvkey', 'VOL':'volume','fyearq':'year','fqtr':'qtr'}, inplace=True)\n",
    "\n",
    "# I have included anndats, previously excluded. \n",
    "merged = merged[[\"cusip\", \"anndats\", \"open\", \"high\", \"low\", \"close\", \"volume\", \"estimate\", \"actual\", \"datadate\", \"year\",\"qtr\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "r = .9523\n",
    "#.968 \n",
    "\n",
    "merged[\"beat\"] = np.where((merged[\"actual\"].map(lambda x: float(x)))>(merged[\"estimate\"].map(lambda x: float(x)/r)),1,0)\n",
    "\n",
    "merged = merged.drop(merged[merged.anndats < merged.datadate].index)\n",
    "\n",
    "merged = merged.drop(merged[(merged.anndats.astype(int) - merged.datadate.astype(int))>11100].index)\n",
    "\n",
    "# df = df.drop(df[df.score < 50].index)\n",
    "\n",
    "merged.set_index(['year', 'qtr', 'cusip' ], inplace=True)\n",
    "\n",
    "merged.drop(\"ticker\", inplace=True)\n",
    "\n",
    "merged.to_csv(\"merged_complete.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This establishes the model framework. \n",
    "\n",
    "def target_f(merged, cusi):\n",
    "    saved = pd.DataFrame()\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    model_frame = new_group[\"beat\"].groupby(level=['year', 'qtr']).agg([np.median]).reset_index()\n",
    "    bruse = model_frame\n",
    "    model_frame.rename(columns={\"median\":\"target\"}, inplace=True)\n",
    "    model_frame = model_frame[\"target\"].astype(int)\n",
    "    saved[\"target_\"+ cusi] = model_frame\n",
    "    saved[\"year\"+ cusi] = bruse[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = bruse[\"qtr\"]\n",
    "    \n",
    "    return saved \n",
    "\n",
    "\n",
    "def mom50_f(merged, cusi): \n",
    "    \n",
    "    saved = pd.DataFrame()\n",
    "    d = pd.DataFrame()\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    d[\"close\"] = new_group[\"close\"]\n",
    "    d.reset_index()\n",
    "\n",
    "    momentums = pd.DataFrame()\n",
    "    ticks = pd.DataFrame()\n",
    "    ticks = d[\"close\"].dropna().as_matrix()\n",
    "    ticks = np.array(ticks,dtype='f8')\n",
    "    mom1 = ta.MOM(ticks, 10)\n",
    "    mom2 = np.where(mom1 > 0, 1, 0)\n",
    "    d[\"mom\"] = mom2\n",
    "\n",
    "    market_df = d[\"mom\"].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    cnt = np.array(market_df['len']).astype(np.float64)\n",
    "    sm  = np.array(market_df['sum']).astype(np.float64)\n",
    "    here= np.where(np.divide(sm,cnt) > 0.5, 1, 0)\n",
    "    saved[\"mom50_\"+ cusi] = here\n",
    "    saved[\"year\"+ cusi] = market_df[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = market_df[\"qtr\"]\n",
    "    return saved \n",
    "    \n",
    "\n",
    "def ma20_f(merged, cusi):\n",
    "    saved = pd.DataFrame()\n",
    "    d = pd.DataFrame()\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    d[\"close\"] = new_group[\"close\"]\n",
    "    #d.reset_index()\n",
    "    \n",
    "    ticks = d[\"close\"].dropna().as_matrix()\n",
    "    ticks = np.array(ticks,dtype='f8')\n",
    "    mom1 = ta.MA(ticks, 20)\n",
    "    df = pd.DataFrame({'mom1':mom1.tolist()})\n",
    "    df = df.fillna(method=\"bfill\")\n",
    "\n",
    "    de = pd.DataFrame({'close':ticks.tolist()})\n",
    "\n",
    "    # NB with the moving averages, you would automatically have those first days cut off.\n",
    "    # You can backfill it, period long enough for that not to be an issue.  \n",
    "\n",
    "    values = (de['close'] - df['mom1'])\n",
    "    mom2 = pd.DataFrame()\n",
    "    d['price_above'] = np.where(values > 0, 1, 0)\n",
    "\n",
    "    #market_df = mom2['price_above'].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    market_df = d['price_above'].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    cnt = np.array(market_df['len']).astype(np.float64)\n",
    "    sm  = np.array(market_df['sum']).astype(np.float64)\n",
    "    here= np.where(np.divide(sm,cnt) > 0.5, 1, 0)\n",
    "    saved[\"ma20_\"+ cusi] = here\n",
    "    saved[\"year\"+ cusi] = market_df[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = market_df[\"qtr\"]\n",
    "\n",
    "    return saved\n",
    "\n",
    "   \n",
    "def day_f(merged, cusi): \n",
    "\n",
    "    saved = pd.DataFrame()\n",
    "    cusip = merged.index.levels[2].unique()\n",
    "\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    d = new_group\n",
    "\n",
    "\n",
    "    d['upday'] = np.where(new_group['close'].convert_objects(convert_numeric=True) - new_group['open'].convert_objects(convert_numeric=True) > 0, 1, 0)\n",
    "\n",
    "\n",
    "    market_df = d[\"upday\"].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    cnt = np.array(market_df['len']).astype(np.float64)\n",
    "    sm  = np.array(market_df['sum']).astype(np.float64)\n",
    "    here= np.where(np.divide(sm,cnt) > 0.5, 1, 0)\n",
    "    saved[\"day_\"+ cusi] = here\n",
    "    saved[\"year\"+ cusi] = market_df[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = market_df[\"qtr\"]\n",
    "    \n",
    "    return saved\n",
    "\n",
    "\n",
    "\n",
    "def ema10_f(merged, cusi):\n",
    "    saved = pd.DataFrame()\n",
    "    d = pd.DataFrame()\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    d[\"close\"] = new_group[\"close\"]\n",
    "    #d.reset_index()\n",
    "\n",
    "    \n",
    "    ticks = d[\"close\"].dropna().as_matrix()\n",
    "    ticks = np.array(ticks,dtype='f8')\n",
    "    mom1 = ta.EMA(ticks, 10)\n",
    "    df = pd.DataFrame({'mom1':mom1.tolist()})\n",
    "    df = df.fillna(method=\"bfill\")\n",
    "\n",
    "    de = pd.DataFrame({'close':ticks.tolist()})\n",
    "\n",
    "    # NB with the moving averages, you would automatically have those first days cut off.\n",
    "    # You can just backfill it, there is noissue in that. \n",
    "\n",
    "    values = (de['close'] - df['mom1'])\n",
    "    mom2 = pd.DataFrame()\n",
    "    d['price_above'] = np.where(values > 0, 1, 0)\n",
    "\n",
    "    #market_df = mom2['price_above'].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    market_df = d['price_above'].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    cnt = np.array(market_df['len']).astype(np.float64)\n",
    "    sm  = np.array(market_df['sum']).astype(np.float64)\n",
    "    here= np.where(np.divide(sm,cnt) > 0.5, 1, 0)\n",
    "    saved[\"ema10_\"+ cusi] = here\n",
    "    saved[\"year\"+ cusi] = market_df[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = market_df[\"qtr\"]\n",
    "\n",
    "    return saved\n",
    "\n",
    "\n",
    "\n",
    "def mom_vol_f(merged, cusi): \n",
    "    \n",
    "    saved = pd.DataFrame()\n",
    "    d = pd.DataFrame()\n",
    "    new_group = merged.xs(cusi, level='cusip')\n",
    "    d[\"volume\"] = new_group[\"volume\"]\n",
    "    d.reset_index()\n",
    "\n",
    "    momentums = pd.DataFrame()\n",
    "    \n",
    "    ticks = d[\"volume\"].dropna().as_matrix()\n",
    "    ticks = np.array(ticks,dtype='f8')\n",
    "    mom1 = ta.MOM(ticks, 10)\n",
    "    mom2 = np.where(mom1 > 0, 1, 0)\n",
    "    d[\"v_mom\"] = mom2\n",
    "\n",
    "    market_df = d[\"v_mom\"].groupby(level=['year', 'qtr']).agg([np.mean, np.sum, np.std, len]).reset_index()\n",
    "\n",
    "    cnt = np.array(market_df['len']).astype(np.float64)\n",
    "    sm  = np.array(market_df['sum']).astype(np.float64)\n",
    "    here= np.where(np.divide(sm,cnt) > 0.5, 1, 0)\n",
    "    saved[\"mom_vol_\"+ cusi] = here\n",
    "    saved[\"year\"+ cusi] = market_df[\"year\"]\n",
    "    saved[\"qtr\"+ cusi] = market_df[\"qtr\"]\n",
    "    \n",
    "    return saved \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dereksnow/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "# Aggregation of features\n",
    "\n",
    "saved = pd.DataFrame()\n",
    "cusip = merged.index.levels[2].unique()\n",
    "\n",
    "day_cusip = pd.DataFrame()\n",
    "day = pd.DataFrame()\n",
    "\n",
    "ma20_cusip = pd.DataFrame()\n",
    "ma20 = pd.DataFrame()\n",
    "\n",
    "mom50_cusip = pd.DataFrame()\n",
    "mom50 = pd.DataFrame()\n",
    "\n",
    "ema10_cusip = pd.DataFrame()\n",
    "ema10 = pd.DataFrame()\n",
    "\n",
    "mom_vol_cusip = pd.DataFrame()\n",
    "mom_vol = pd.DataFrame()\n",
    "\n",
    "target_cusip = pd.DataFrame()\n",
    "target = pd.DataFrame()\n",
    "\n",
    "\n",
    "for cusi in cusip:\n",
    "    day_cusip = day_f(merged, cusi)\n",
    "    day = pd.concat((day, day_cusip),axis=1) \n",
    "   \n",
    "    ma20_cusip = ma20_f(merged, cusi)\n",
    "    ma20 = pd.concat((ma20,ma20_cusip), axis=1)\n",
    "    \n",
    "    mom50_cusip = mom50_f(merged, cusi)\n",
    "    mom50 = pd.concat((mom50,mom50_cusip),axis=1)\n",
    "    \n",
    "    ema10_cusip = ema10_f(merged, cusi)\n",
    "    ema10 = pd.concat((ema10,ema10_cusip), axis=1)\n",
    "    \n",
    "    mom_vol_cusip = mom_vol_f(merged, cusi)\n",
    "    mom_vol = pd.concat((mom_vol ,mom_vol_cusip),axis=1)\n",
    "    \n",
    "    target_cusip = target_f(merged, cusi)\n",
    "    target = pd.concat((target, target_cusip), axis=1)\n",
    "    \n",
    "    \n",
    "varlist = {\"target_\":target,\n",
    "           \"day_\":day,\n",
    "           \"ma20_\":ma20,\n",
    "           \"mom50_\":mom50,\n",
    "           \"ema10_\":ema10,\n",
    "           \"mom_vol_\":mom_vol}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## All of this create the time dummies data. \n",
    "\n",
    "keys = [c for c in day if c.startswith(\"year\")]\n",
    "frame_1 = pd.melt(day, value_vars=keys, value_name=\"year\")\n",
    "\n",
    "keys = [c for c in day if c.startswith(\"qtr\")]\n",
    "frame_2 = pd.melt(day, value_vars=keys, value_name=\"qtr\")\n",
    "\n",
    "frame = pd.concat((frame_1,frame_2), axis=1)\n",
    "avg = frame \n",
    "\n",
    "cols_to_transform = ['year', 'qtr']\n",
    "frame = pd.get_dummies(avg, columns = cols_to_transform)\n",
    "frame = pd.concat((frame, avg), axis=1)\n",
    "\n",
    "frame[\"myver\"] = frame.ix[:,[1]]\n",
    "frame = frame.drop([\"variable\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame.to_csv(\"framecsv.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame_full = pd.DataFrame()\n",
    "\n",
    "for i, v in varlist.iteritems():\n",
    "    keys = [c for c in v if c.startswith(i)]\n",
    "    frame_a = pd.melt(v, value_vars=keys, value_name=i)\n",
    "    frame_full = pd.concat((frame_full,frame_a), axis=1)\n",
    " \n",
    "\n",
    "frame_full_1 = frame_full.drop([\"variable\"], axis=1)\n",
    "fire = frame_full_1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fire.to_csv(\"fire3444.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fire_1 = pd.concat((fire, frame), axis=1)\n",
    "\n",
    "\"\"\"\n",
    "fire.to_csv(\"fire.csv\")\n",
    "\n",
    "frame.to_csv(\"frame.csv\")\n",
    "\"\"\"\n",
    "\n",
    "frame_full = fire_1\n",
    "frame_full = frame_full.drop_duplicates()\n",
    "frame_full = frame_full.dropna()\n",
    "\n",
    "frame_full = frame_full.dropna()\n",
    "frame_full.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#frame_full.reset_index(inplace=True, drop=True)\n",
    "#frame_full = frame_full.drop_duplicates()\n",
    "\n",
    "##########################\n",
    "\n",
    "frame_full[\"target_p\"] = frame_full[\"target_\"].shift(-1)\n",
    "frame_full[\"target_p2\"] = frame_full[\"target_\"].shift(-2)\n",
    "\n",
    "X_first_1 = frame_full \n",
    "X_first_1 = X_first_1.drop([\"myver\", \"year\", \"qtr\"],axis=1)\n",
    "X_first = X_first_1.dropna(axis=0)\n",
    "\n",
    "#fire_1.to_csv(\"fire_1.csv\")\n",
    "#frame_full.to_csv(\"frame_full.csv\")\n",
    "\n",
    "\n",
    "##########################\n",
    "\n",
    "# -------------------- Here is where I create all the alternative targets. \n",
    "\n",
    "bloom = frame_full[[\"year\", \"qtr\", \"myver\", \"target_\"]]\n",
    "\n",
    "bloom_1 = bloom.set_index(['year', 'qtr'])\n",
    "\n",
    "here = bloom_1.groupby(level=['year', 'qtr']).mean()\n",
    "\n",
    "here_1 = here.reset_index()\n",
    "\n",
    "here_1.rename(columns={'target_': 'ind_target'}, inplace=True)\n",
    "\n",
    "framed = pd.merge(frame_full, here_1, on=[\"year\",\"qtr\"], how=\"outer\")\n",
    "\n",
    "framed.to_csv(\"framed.csv\")\n",
    "\n",
    "#framed.rename(columns={'target_': 'ind_target'}, inplace=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_first.to_csv(\"X_first.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dereksnow/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nframe_edit_1['yr'] = pd.Categorical.from_array(frame_edit_1.year).codes\\n\\nle = LabelEncoder().fit(frame_edit_1.year) \\n\\nyr = le.transform(frame_edit_1.year)\\n\\nclasses = list(le.classes_)\\n\""
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This feauture was not contributary. \n",
    "\n",
    "# frame_full[\"target_x2\"] = frame_full[\"target_\"].shift(-2) if frame_full[\"target_\"].shift(-1) == frame_full[\"target_\"].shift(-2)\n",
    "# frame_full[\"target_x2\"] = np.where(np.logical_and(frame_full[\"target_\"].shift(-3) == frame_full[\"target_\"].shift(-2), frame_full[\"target_\"].shift(-2) == 1), 1,0)\n",
    "# This one actually killed me, its addition led to worse results\n",
    "\n",
    "\n",
    "framed_1 = framed.dropna(axis=0)\n",
    "\n",
    "framed_1.reset_index(inplace=True, drop=True)\n",
    "\n",
    "framed_1.drop([\"myver\", \"year\", \"qtr\"],axis=1,inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "framed_1.to_csv(\"framed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = X_first.drop([\"target_\"], axis=1)\n",
    "\n",
    "# X_first performs slightly better than framed_1  \n",
    "\n",
    "# Two alternatives, X_first of framed_1\n",
    "\n",
    "# ind_target. \n",
    "\n",
    "y = X_first[\"target_\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### For data transfer\n",
    "#y = y.to_frame()\n",
    "### y should be series if not trnasfering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#X.to_csv(\"X.csv\")\n",
    "#y.to_csv(\"y.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state=43)\n",
    "\n",
    "# 0.33, 43\n",
    "\n",
    "this = sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.43787672564650981"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "this\n",
    "#bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "0.574761812172\n",
      "Accuracy: 57.4762%\n",
      "Log Loss: 3.14670788089\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "0.626288158662\n",
      "Accuracy: 62.6288%\n",
      "Log Loss: 0.641415690609\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "0.595177911725\n",
      "Accuracy: 59.5178%\n",
      "Log Loss: 3.95943025223\n",
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "0.596733424072\n",
      "Accuracy: 59.6733%\n",
      "Log Loss: 1.55418647091\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "0.640676647871\n",
      "Accuracy: 64.0677%\n",
      "Log Loss: 0.691001912187\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "0.640871086914\n",
      "Accuracy: 64.0871%\n",
      "Log Loss: 0.637834495096\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "0.621816060665\n",
      "Accuracy: 62.1816%\n",
      "Log Loss: 0.769997339871\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "\n",
    "\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "framed = np.array\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    name = clf.__class__.__name__\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    y_predict = clf.predict(X_test)\n",
    "    print metrics.accuracy_score(y_test, y_predict)\n",
    "    acc = accuracy_score(y_test, y_predict)\n",
    "    \n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    \n",
    "    #scores = cross_val_score(clf, X , y , cv=5)\n",
    "    #print scores\n",
    "    #print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2)) \n",
    "    \n",
    "    \n",
    "    ###\n",
    "    #print y_predict\n",
    "    #print y_test.as_matrix()\n",
    "    \n",
    "    y_predict = clf.predict_proba(X_test)\n",
    "    ll = log_loss(y_test, y_predict)\n",
    "    print(\"Log Loss: {}\".format(ll))\n",
    "    \n",
    "    #print y_predict\n",
    "    #print y_test.as_matrix()\n",
    "    \n",
    "    log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols)\n",
    "    log = log.append(log_entry)\n",
    "    \n",
    "    # However at this step we still haven't looped and walked through the different KNNs.\n",
    "    #scores = cross_val_score(clf, X, y, cv=10, scoring='accuracy')\n",
    "    # Here we folded 10 times, this has nothing to do with the previous cell, we have not incorporated the 5 split]\n",
    "    \n",
    "print(\"=\"*30)\n",
    "\n",
    "# Cross val is not actually neede you dont need that extra 20%, already have enough data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.57353184449958639, 0.56658395368072789, 0.60397022332506201, 0.59851116625310175, 0.62580645161290327, 0.6165425971877585, 0.63225806451612898, 0.62861869313482222, 0.6387096774193548, 0.63291976840363939, 0.63622828784119112, 0.64251447477253931, 0.64267990074441683, 0.64168734491315138, 0.64582299421009104, 0.64267990074441683, 0.64946236559139781, 0.64681555004135649, 0.64747725392886679, 0.65144747725392882, 0.64863523573200987, 0.64698097601323412, 0.6512820512820513, 0.64747725392886679, 0.64946236559139781]\n"
     ]
    }
   ],
   "source": [
    "k_range = range(1,26)\n",
    "# I think range just instantiates a vector variable\n",
    "# Below is also an instantiation of a vector variable\n",
    "scores = []\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "\n",
    "print scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
